Probabilistic Model Checking using PRISM \cite{Kwiatkowskaprism2011} relies on constructing a formal model, typically represented using appropriate storage structures. The verification process is then performed by applying a suite of algorithms implemented within the PRISM engine \cite{engines}. For our analysis, we employ Continuous-Time Markov Chains (CTMCs) \cite{Kwiatkowska2007}, a well-established modeling technique for evaluating reliability and performance. The CTMC involves a set of states and a transition matrix \emath{\textbf{R}: S \times S \rightarrow \mathbb{R}_{\geq 0}}.  The rate specifies the delay before a transition between states s and s' takes place \emath{\textbf{R}(s,s')}, where the probability between \emath{s} and \emath{s'} take within time t is given by the value \emath{1-e^{-\textbf{R}(s,s') \times t}}. Based on research using PRISM for CTMC modeling, as outlined in \cite{prismctmc}, exponentially distributed delays are often considered suitable for modeling electronic component lifetimes and inter-arrival times. 

The PRISM model is composed of a set of modules that can synchronize. Each module is characterized by variables and commands (or transitions). The valuations of these variables represent the state of the module. The behavior of each module is described using a set of commands, each of which follows the following format:
\[
[a] \ g \ \rightarrow \ \lambda: u
\]
This indicates that if the guard condition \( g \) evaluates to true, then the update \( u \) is enabled to occur with a rate of \( \lambda \) for action \( a \). A guard is a boolean formula constructed from the module variables. The update \( u \) is an evaluation of variables expressed as a conjunction of assignments: \emath{v_{i}' = val_{i} + \ldots + v_{n}' = val_{n}} where \( v_{i} \in V \), with \( V \) being a set of local and global variables, and \( val_{i} \) are values evaluated via expressions denoted by \( \theta \) such that \( \theta: V \rightarrow \mathbb{D} \), where \( \mathbb{D} \) is the domain of the variables.

Two types of reward functions are highlighted. The action reward function assigns a real value to each state-action. This value is accumulated when the action \( a \) is selected in the state \( s \). Additionally, the state reward function, denoted as \( r_{S} : S \longrightarrow \mathbb{R} \), assigns a real value to each state \( s \). This value is accumulated when the state \( s \) is reached.

Properties are typically expressed in Continuous Stochastic Logic (CSL) \cite{kwiatkowska2002approximate}, a stochastic variant of the well-known Computational Tree Logic (CTL).  For instance, the following property expressed in natural language: \emph{Is the probability of that eventually the system failure occurring within 100 time units is less than 0.001} is expressed  as: \emath{ P_{<0.001} [ F^{\leq 100} \ fail ]}
Here, \(fail\) is the label that refers to the system failure states. 
Regarding the reward structure, the property expressed in natural language: \emph{What is the amount of reward accumulated over a specific 100 times units ?} is expressed in CSL as:
\emath{ R\{"up"\}=? [C \leq 100]}.

